{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea083963-93e2-42c1-819d-41eb79ed0f91",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import min, max, col\n",
    "\n",
    "# Load the data\n",
    "df = spark.table(\"tabular.dataexpert.population_data_silver\")\n",
    "\n",
    "# Define window for ZIP code groups\n",
    "from pyspark.sql.window import Window\n",
    "zip_window = Window.partitionBy(\"ZIP\")\n",
    "\n",
    "# Compute min/max latitude and longitude per ZIP\n",
    "df_bounds = df.withColumn(\"min_lat\", min(col(\"LATITUDE\")).over(zip_window)) \\\n",
    "              .withColumn(\"max_lat\", max(col(\"LATITUDE\")).over(zip_window)) \\\n",
    "              .withColumn(\"min_lon\", min(col(\"LONGITUDE\")).over(zip_window)) \\\n",
    "              .withColumn(\"max_lon\", max(col(\"LONGITUDE\")).over(zip_window))\n",
    "\n",
    "df_bounds = df_bounds.select(\"ZIP\", \"min_lat\", \"max_lat\", \"min_lon\", \"max_lon\").dropDuplicates()\n",
    "df_bounds.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8acd105d-132e-4025-b996-1ec68b088a74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when, udf\n",
    "import math\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "# Approximate radius of Earth in kilometers\n",
    "R = 6371.0  \n",
    "\n",
    "# Function to calculate haversine distance\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))\n",
    "    return R * c\n",
    "\n",
    "# Apply Haversine formula in PySpark\n",
    "haversine_udf = udf(lambda lat1, lon1, lat2, lon2: haversine_distance(lat1, lon1, lat2, lon2), DoubleType())\n",
    "\n",
    "df_area = df_bounds.withColumn(\"lat_distance_km\", haversine_udf(col(\"min_lat\"), col(\"min_lon\"), col(\"max_lat\"), col(\"min_lon\"))) \\\n",
    "                   .withColumn(\"lon_distance_km\", haversine_udf(col(\"min_lat\"), col(\"min_lon\"), col(\"min_lat\"), col(\"max_lon\")))\n",
    "\n",
    "# Compute approximate area\n",
    "df_area = df_area.withColumn(\"land_area_sq_km\", col(\"lat_distance_km\") * col(\"lon_distance_km\"))\n",
    "\n",
    "df_area = df_area.withColumn(\n",
    "    \"land_area_sq_km\",\n",
    "    when(col(\"land_area_sq_km\") == 0, 1).otherwise(col(\"land_area_sq_km\"))\n",
    ")\n",
    "\n",
    "#display(df_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "325b3cfa-9f01-46bf-ba4d-9b055f7c739a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, expr\n",
    "\n",
    "# Join land area data with population data\n",
    "df_final = df.join(df_area.select(\"ZIP\", \"land_area_sq_km\"), \"ZIP\", \"left\")\n",
    "\n",
    "# Compute Population Density using try_divide\n",
    "df_final = df_final.withColumn(\"population_density\", expr(\"try_divide(TOTAL_POPULATION, land_area_sq_km)\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82259199-27f5-4f82-94f5-ced1bc137271",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_final.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"tabular.dataexpert.population_data_gold\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "load_population_density_gold",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
